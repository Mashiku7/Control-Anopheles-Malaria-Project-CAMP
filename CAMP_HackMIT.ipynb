{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAMP HackMIT.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "cs2Bgz5JNh9H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Time series forecasting  maleria prevelance in Muleba using ARIMA"
      ]
    },
    {
      "metadata": {
        "id": "puq7p8FthHSQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.1f}'.format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K8VTQpKijXO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "491e3a6f-2496-48ff-e5fd-5b80aef70a91"
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv( 'https://raw.githubusercontent.com/Mashiku7/Control-Anopheles-Malaria-Project-CAMP/master/CDO6199837732377EnviromentData.csv',  index_col='STA')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7994734b7bb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'https://raw.githubusercontent.com/Mashiku7/Control-Anopheles-Malaria-Project-CAMP/master/CDO6199837732377EnviromentData.csv'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'STA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1067\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_date_conversions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m             \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malldata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m         \u001b[0;31m# maybe create a mi on the columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_index\u001b[0;34m(self, data, alldata, columns, indexnamerow)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_complex_date_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1411\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_simple_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malldata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1412\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agg_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_complex_date_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_get_simple_index\u001b[0;34m(self, data, columns)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m             \u001b[0mto_remove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mix\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m   1436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Index %s invalid'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Index STA invalid"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "JAOxL0KmjfWW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Examine Data"
      ]
    },
    {
      "metadata": {
        "id": "fyXd42B8jeaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d2f6601-928c-4f73-f279-5853346465b4"
      },
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2bb0b18689d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "3I2P9Uf3rcR6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b726071e-3f7b-4bca-8997-22791fb74663"
      },
      "cell_type": "code",
      "source": [
        "data.index"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e47a7d363e09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "mqJTe2Turk9R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5d4a865-62bb-46bb-c9e1-5617fba07093"
      },
      "cell_type": "code",
      "source": [
        "ts = data[\"ANOPHELES\"] \n",
        "ts.head(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-94146c019b21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ANOPHELES\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "4g-Wj8vssW4l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad16d7ac-f3b8-4c48-bbb9-c355ea6151c6"
      },
      "cell_type": "code",
      "source": [
        "ts['637290']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6ed60d6d4ecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'637290'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ts' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "dxYlZwDmuM-I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Checking the stations\n",
        "\n",
        "we have Station ID, Day(Time stamp) and Density time series data then create the time-series\n",
        "\n",
        "Mean = constant over all intervals.\n",
        "Variance = constant over all intervals."
      ]
    },
    {
      "metadata": {
        "id": "TLusRiw_uo8d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(ts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cAvJnz3Du81b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.stattools import adfuller\n",
        "def test_stationarity(timeseries):\n",
        "    \n",
        "    #Determing rolling statistics\n",
        "    rolmean = timeseries.rolling(window=12).mean()\n",
        "    rolstd = timeseries.rolling(window=12).std()\n",
        "\n",
        "    #Plot rolling statistics:\n",
        "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
        "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
        "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
        "    plt.legend(loc='best')\n",
        "    plt.title('Rolling Mean & Standard Deviation')\n",
        "    plt.show(block=False)\n",
        "    \n",
        "    #Perform Dickey-Fuller test:\n",
        "    print 'Results of Dickey-Fuller Test:'\n",
        "    dftest = adfuller(timeseries, autolag='AIC')\n",
        "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
        "    for key,value in dftest[4].items():\n",
        "        dfoutput['Critical Value (%s)'%key] = value\n",
        "    print dfoutput"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1qeX0q7jvKyF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_stationarity(ts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WbE3OH7UvxuF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ts_log = np.log(ts)\n",
        "plt.plot(ts_log)\n",
        "ts_smooth = ts_log.rolling(window = 12).mean()\n",
        "plt.plot(ts_smooth, color = 'red')\n",
        "plt.plot(ts_log)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ksry0mAYwLGn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Forecasting\n",
        "Lets make model on the TS after differencing as it is a very popular technique. Also, its relatively easier to add noise and seasonality back into predicted residuals in this case. Having performed the trend and seasonality estimation techniques, there can be two situations:\n",
        "\n",
        "A strictly stationary series with no dependence among the values. This is the easy case wherein we can model the residuals as white noise. But this is very rare.\n",
        "A series with significant dependence among values. In this case we need to use some statistical models like ARIMA to forecast the data.\n",
        "Let me give you a brief introduction to ARIMA. I won’t go into the technical details but you should understand these concepts in detail if you wish to apply them more effectively. ARIMA stands for Auto-Regressive Integrated Moving Averages. The ARIMA forecasting for a stationary time series is nothing but a linear (like a linear regression) equation. The predictors depend on the parameters (p,d,q) of the ARIMA model:\n",
        "\n",
        "Number of AR (Auto-Regressive) terms (p): AR terms are just lags of dependent variable. For instance if p is 5, the predictors for x(t) will be x(t-1)….x(t-5).\n",
        "Number of MA (Moving Average) terms (q): MA terms are lagged forecast errors in prediction equation. For instance if q is 5, the predictors for x(t) will be e(t-1)….e(t-5) where e(i) is the difference between the moving average at ith instant and actual value.\n",
        "Number of Differences (d): These are the number of nonseasonal differences, i.e. in this case we took the first order difference. So either we can pass that variable and put d=0 or pass the original variable and put d=1. Both will generate same results.\n",
        "Selecting p, q, and d values\n",
        "\n",
        "Autocorrelation Function (ACF): It is a measure of the correlation between the the TS with a lagged version of itself. For instance at lag 5, ACF would compare series at time instant ‘t1’…’t2’ with series at instant ‘t1-5’…’t2-5’ (t1-5 and t2 being end points).\n",
        "Partial Autocorrelation Function (PACF): This measures the correlation between the TS with a lagged version of itself but after eliminating the variations already explained by the intervening comparisons. Eg at lag 5, it will check the correlation but remove the effects already explained by lags 1 to 4."
      ]
    },
    {
      "metadata": {
        "id": "Uml00K3zwTXj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#ACF and PACF plots:\n",
        "from statsmodels.tsa.stattools import acf, pacf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-wx-QTE1wexz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lag_acf = acf(ts_diff, nlags=20)\n",
        "lag_pacf = pacf(ts_diff, nlags=20, method='ols')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bPAQc39uwiix",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Plot ACF: \n",
        "plt.subplot(121) \n",
        "plt.plot(lag_acf)\n",
        "plt.axhline(y=0,linestyle='--',color='gray')\n",
        "plt.axhline(y=-1.96/np.sqrt(len(ts_diff)),linestyle='--',color='gray')\n",
        "plt.axhline(y=1.96/np.sqrt(len(ts_diff)),linestyle='--',color='gray')\n",
        "plt.title('Autocorrelation Function')\n",
        "\n",
        "#Plot PACF:\n",
        "plt.subplot(122)\n",
        "plt.plot(lag_pacf)\n",
        "plt.axhline(y=0,linestyle='--',color='gray')\n",
        "plt.axhline(y=-1.96/np.sqrt(len(ts_diff)),linestyle='--',color='gray')\n",
        "plt.axhline(y=1.96/np.sqrt(len(ts_diff)),linestyle='--',color='gray')\n",
        "plt.title('Partial Autocorrelation Function')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OBa-24MTwqAr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.arima_model import ARIMA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gf_0ztn_xsKq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "p = 2, q = 2\n",
        "\n",
        "Now AR, MA & ARIMA models for the data"
      ]
    },
    {
      "metadata": {
        "id": "MI-egsIowuJf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "AR Model"
      ]
    },
    {
      "metadata": {
        "id": "tFcNIxMUw42C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = ARIMA(ts_log, order=(2, 1, 0))  \n",
        "results_AR = model.fit(disp=-1)  \n",
        "plt.plot(ts_diff)\n",
        "plt.plot(results_AR.fittedvalues, color='red')\n",
        "plt.title('RSS: %.4f'% sum((results_AR.fittedvalues-ts_diff)**2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "At0tk3L7w9fU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# MA model\n",
        "\n",
        "model = ARIMA(ts_log, order=(0, 1, 2))  \n",
        "results_AR = model.fit(disp=-1)  \n",
        "plt.plot(ts_diff)\n",
        "plt.plot(results_AR.fittedvalues, color='red')\n",
        "plt.title('RSS: %.4f'% sum((results_AR.fittedvalues-ts_diff)**2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rP_dt4t7yDIU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ARIMA model\n",
        "# Goal for the forecase was RSS: 1.275 and \n",
        "\n",
        "model = ARIMA(ts_log, order=(2, 1, 2))  \n",
        "results_AR = model.fit(disp=-1)  \n",
        "plt.plot(ts_diff)\n",
        "plt.plot(results_AR.fittedvalues, color='red')\n",
        "plt.title('RSS: %.4f'% sum((results_AR.fittedvalues-ts_diff)**2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yPL_V7KSybbO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "preds = pd.Series(results_AR.fittedvalues, copy = True)\n",
        "preds_cumsum = preds.cumsum()\n",
        "print preds_cumsum.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0n3gHBsEyj9S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "preds_log = pd.Series(ts_log.ix[0], index=ts_log.index)\n",
        "preds_log = preds_log.add(preds_cumsum,fill_value=0)\n",
        "preds_log.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0xpr9FVHyoim",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "preds_ARIMA = np.exp(preds_log)\n",
        "plt.plot(ts)\n",
        "plt.plot(preds_ARIMA)\n",
        "plt.title('RMSE: %.4f'% np.sqrt(sum((preds_ARIMA-ts)**2)/len(ts)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TgAwUk5iy00D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The results has a .443 confidences score, not very good but it makes sense with the amount of data. With more work and time with our datasets we will be able to train the agent and add our revised ARIMA model to act as a major argument to our requirements function(Functions that restrict the model form simply placing things everywhere, for example a cost model that allows the agent to spend a max budget per a station region)"
      ]
    },
    {
      "metadata": {
        "id": "RTXPSnoV1N30",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following is our agent so far but due to time constraints at HackMIT we didnt work on the training, evaluation and functions for the agent"
      ]
    },
    {
      "metadata": {
        "id": "spUo0L_o1E-i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import deque\n",
        "\n",
        "class Agent:\n",
        "\tdef __init__(self, state_size, is_eval=False, model_name=\"\"):\n",
        "\t\tself.state_size = state_size # normalized previous days\n",
        "\t\tself.action_size = 3 # sit, buy, sell\n",
        "\t\tself.memory = deque(maxlen=1000)\n",
        "\t\tself.inventory = []\n",
        "\t\tself.model_name = model_name\n",
        "\t\tself.is_eval = is_eval\n",
        "\n",
        "\t\tself.gamma = 0.95\n",
        "\t\tself.epsilon = 1.0\n",
        "\t\tself.epsilon_min = 0.01\n",
        "\t\tself.epsilon_decay = 0.995\n",
        "\n",
        "\t\tself.model = load_model(\"models/\" + model_name) if is_eval else self._model()\n",
        "\n",
        "\tdef _model(self):\n",
        "\t\tmodel = Sequential()\n",
        "\t\tmodel.add(Dense(units=64, input_dim=self.state_size, activation=\"relu\"))\n",
        "\t\tmodel.add(Dense(units=32, activation=\"relu\"))\n",
        "\t\tmodel.add(Dense(units=8, activation=\"relu\"))\n",
        "\t\tmodel.add(Dense(self.action_size, activation=\"linear\"))\n",
        "\t\tmodel.compile(loss=\"mse\", optimizer=Adam(lr=0.001))\n",
        "\n",
        "\t\treturn model\n",
        "\n",
        "\tdef act(self, state):\n",
        "\t\tif not self.is_eval and random.random() <= self.epsilon:\n",
        "\t\t\treturn random.randrange(self.action_size)\n",
        "\n",
        "\t\toptions = self.model.predict(state)\n",
        "\t\treturn np.argmax(options[0])\n",
        "\n",
        "\tdef expReplay(self, batch_size):\n",
        "\t\tmini_batch = []\n",
        "\t\tl = len(self.memory)\n",
        "\t\tfor i in range(l - batch_size + 1, l):\n",
        "\t\t\tmini_batch.append(self.memory[i])\n",
        "\n",
        "\t\tfor state, action, reward, next_state, done in mini_batch:\n",
        "\t\t\ttarget = reward\n",
        "\t\t\tif not done:\n",
        "\t\t\t\ttarget = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
        "\n",
        "\t\t\ttarget_f = self.model.predict(state)\n",
        "\t\t\ttarget_f[0][action] = target\n",
        "\t\t\tself.model.fit(state, target_f, epochs=1, verbose=0)\n",
        "\n",
        "\t\tif self.epsilon > self.epsilon_min:\n",
        "\t\t\tself.epsilon *= self.epsilon_decay \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q-p5KXXy4kpn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Thanks to Ravindra for ARIMA tutorial for time-series\n",
        "\n",
        "https://github.com/aliasvishnu\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "bLVZXpXz1iVu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Acknowledgements to Google Colab Import code snippets, Tensorflow Documentation, Siraj Raval ARIMA Stock Market forcasting video, Malaria Atlas Project (MAP), IBM Research Kenya, WHO, NASA GPM, Icesat, Lansat, Consults by Ms. Wright, Ms. Battle, Ms. Casasanto\n"
      ]
    },
    {
      "metadata": {
        "id": "tflXgvCi2fCR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And than you to HackMIT 2018 for an amazing and Inspiring weekend, and the IBM, Microsoft mentors"
      ]
    }
  ]
}